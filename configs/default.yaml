subcommand: fit
fit:
  seed_everything: 42
  trainer:
    accelerator: auto
    devices: 1
    max_epochs: 99
    gradient_clip_val: 1.0
    log_every_n_steps: 50
    enable_model_summary: true
    callbacks:
      - class_path: lightning.pytorch.callbacks.ModelCheckpoint
        init_args:
          monitor: val/loss
          mode: min
          save_top_k: 1
          save_last: true
          filename: shakespeare-{epoch:02d}-{val_loss:.2f}
      - class_path: lightning.pytorch.callbacks.ModelCheckpoint
        init_args:
          every_n_epochs: 2
          save_top_k: -1
          filename: shakespeare-epoch{epoch:02d}
      - class_path: lightning.pytorch.callbacks.EarlyStopping
        init_args:
          monitor: val/loss
          mode: min
          patience: 3
      - class_path: lightning.pytorch.callbacks.LearningRateMonitor
        init_args:
          logging_interval: step
  model:
    class_path: models.CharDecoderTransformer
    init_args:
      vocab_size: 0
      max_sequence_length: 128
      d_model: 256
      num_layers: 4
      num_heads: 8
      mlp_ratio: 4.0
      dropout: 0.1
      label_smoothing: 0.0
      learning_rate: 0.0003
      weight_decay: 0.01
      optimizer_betas:
        - 0.9
        - 0.95
      optimizer_eps: 1e-8
      warmup_steps: 200
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: trm-lit
      name: shakespeare-char-transformer
      save_dir: logs
      log_model: false
      offline: false
  data:
    class_path: datasets.ShakespeareDataModule
    init_args:
      data_dir: data/shakespeare
      sequence_length: 128
      batch_size: 64
      num_workers: 0
      train_fraction: 0.9
      pin_memory: true
      persistent_workers: false
